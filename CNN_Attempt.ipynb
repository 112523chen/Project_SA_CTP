{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "MutinomialNB with TfidVectorizer on Original Dataset \n",
    "\n",
    "- cleaned: accuracy - 0.65\n",
    "\n",
    "- cleaned and stemmed: accuracy - 0.69\n",
    "\n",
    "- cleaned and lemmized: accuracy - 0.70\n",
    "\n",
    "MutinomialNB with CountVectorizer on Original Dataset \n",
    "\n",
    "- cleaned: accuracy - 0.77\n",
    "\n",
    "- cleaned and stemmed: accuracy - 0.77\n",
    "\n",
    "- cleaned and lemmized: accuracy - 0.80\n",
    "\n",
    "- cleaned and dropped surprised label: accuracy - 0.83 (Best Model on Original Dataset)\n",
    "\n",
    "MutinomialNB with TfidVectorizer on Second Dataset (First 10_000)\n",
    "\n",
    "- cleaned: accuracy - 0.87\n",
    "\n",
    "- cleaned and stemmed: accuracy - 0.84\n",
    "\n",
    "- cleaned and lemmized: accuracy - 0.87\n",
    "\n",
    "MutinomialNB with CountVectorizer on Second Dataset (First 10_000)\n",
    "\n",
    "- cleaned: accuracy - 0.86\n",
    "\n",
    "- cleaned and stemmed: accuracy - 0.84\n",
    "\n",
    "- cleaned and lemmized: accuracy - 0.88 (Best Model on Second Dataset) (Live Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import File Based Libraries\n",
    "import pickle\n",
    "\n",
    "# Import Data Wrangling Libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "\n",
    "# Import Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Machine Learning Libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Import NLP Libraries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    " \n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.utils import to_categorical, np_utils\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Embedding, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataframes from Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split up data with train and test \n",
    "train_df = pd.read_csv(\"data/original_data/training.csv\")\n",
    "test_df = pd.read_csv(\"data/original_data/test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following \n",
    "https://coderzcolumn.com/tutorials/artificial-intelligence/keras-cnn-with-conv1d-for-text-classification#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text, Y_train = [], []\n",
    "for X in train_df['text']:\n",
    "    X_train_text.append(X)\n",
    "for Y in train_df['label']:\n",
    "    Y_train.append(Y)\n",
    "    \n",
    "    \n",
    "X_test_text, Y_test = [], []\n",
    "for X in test_df['text']:\n",
    "    X_test_text.append(X)\n",
    "for Y in test_df['label']:\n",
    "    Y_test.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2000)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_classes = list(set(Y_train))\n",
    "target_classes = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "## Subtracted 1 from labels to bring range from 1-4 to 0-3\n",
    "Y_train, Y_test = np.array(Y_train) - 1, np.array(Y_test) - 1\n",
    "\n",
    "len(X_train_text), len(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  138    2  642    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   1   39  100   59    7   14  532    4   14 3764  548   31   59   61\n",
      "   128  146   73 1593    3   21 1344    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [  15 2945    6 1172    4  289    1    2  462  414    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((16000, 50), (2000, 50))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = 50 ## Hyperparameter\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_text+X_test_text)\n",
    "\n",
    "## Vectorizing data to keep 50 words per sample.\n",
    "X_train_vect = pad_sequences(tokenizer.texts_to_sequences(X_train_text), maxlen=max_tokens, padding=\"post\", truncating=\"post\", value=0.)\n",
    "X_test_vect  = pad_sequences(tokenizer.texts_to_sequences(X_test_text), maxlen=max_tokens, padding=\"post\", truncating=\"post\", value=0.)\n",
    "\n",
    "print(X_train_vect[:3])\n",
    "\n",
    "X_train_vect.shape, X_test_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confused\n",
      "i didnt feel humiliated\n"
     ]
    }
   ],
   "source": [
    "## What is word 444\n",
    "\n",
    "print(tokenizer.index_word[444])\n",
    "\n",
    "## How many times it comes in first text document??\n",
    "\n",
    "print(X_train_text[0]) ## 2 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 50, 128)           2071680   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 50, 32)            28704     \n",
      "                                                                 \n",
      " tf.math.reduce_max (TFOpLam  (None, 32)               0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,100,582\n",
      "Trainable params: 2,100,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 21:33:36.905368: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "embed_len = 128\n",
    "\n",
    "inputs = Input(shape=(max_tokens, ))\n",
    "embeddings_layer = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=embed_len,  input_length=max_tokens)\n",
    "conv = Conv1D(32, 7, padding=\"same\") ## Channels last\n",
    "dense = Dense(len(target_classes), activation=\"softmax\")\n",
    "\n",
    "x = embeddings_layer(inputs)\n",
    "x = conv(x)\n",
    "x = tensorflow.reduce_max(x, axis=1)\n",
    "output = dense(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 21:34:08.664645: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at sparse_xent_op.cc:103 : INVALID_ARGUMENT: Received a label value of -1 which is outside the valid range of [0, 6).  Label values: 0 0 -1 4 3 -1 -1 0 0 3 3 -1 0 -1 -1 2 0 -1 0 0 0 0 0 0 3 3 -1 -1 0 2 0 -1 2 1 0 3 4 2 1 1 1 1 0 0 0 0 3 3 3 3 2 -1 -1 0 -1 -1 0 3 0 0 2 -1 3 0 1 0 0 -1 -1 3 0 3 4 4 0 0 0 0 0 0 -1 0 1 1 -1 0 0 1 -1 0 0 0 1 -1 0 -1 2 -1 0 0 -1 3 -1 0 -1 0 1 -1 -1 0 -1 0 0 2 2 2 -1 1 1 3 0 4 -1 -1 -1 -1 -1 -1 0 3 0 -1 2 0 -1 -1 2 0 0 -1 -1 -1 0 -1 2 -1 -1 2 0 -1 -1 2 3 0 -1 3 0 0 -1 0 2 2 -1 -1 1 2 0 2 3 3 2 0 0 4 0 0 -1 -1 0 2 2 0 1 0 2 0 2 1 3 -1 4 3 -1 1 -1 0 2 0 2 1 1 3 -1 3 2 -1 0 3 0 3 -1 0 0 -1 2 -1 3 -1 0 0 0 0 2 4 0 -1 -1 -1 -1 0 2 3 -1 1 1 3 0 4 1 0 0 0 0 -1 -1 0 2 -1 0 -1 1 -1 3 0 -1 3 -1 3 0 2 4 2 0 -1 2 0 2 0 -1 1 -1 0 0 4 4 3 -1 -1 2 2 2 -1 -1 3 0 -1 1 -1 -1 -1 1 0 0 -1 3 -1 2 3 1 -1 1 0 -1 0 2 2 0 3 0 0 2 1 3 3 0 1 2 0 0 -1 2 -1 3 4 0 0 -1 0 -1 -1 -1 3 2 3 -1 0 0 2 1 0 0 2 3 2 3 -1 2 0 0 -1 3 2 0 -1 0 0 0 -1 0 1 3 0 0 0 0 1 -1 3 0 -1 -1 2 -1 -1 0 2 -1 2 3 -1 4 2 2 -1 2 0 -1 0 3 -1 0 0 3 0 -1 3 0 0 -1 0 -1 1 -1 0 0 3 0 0 3 0 0 -1 3 2 -1 -1 0 2 2 1 1 0 1 3 2 2 4 -1 -1 2 0 0 0 2 -1 0 0 0 3 2 -1 0 2 0 0 0 2 2 -1 0 0 3 -1 0 1 -1 0 3 -1 0 -1 3 0 4 3 -1 3 -1 -1 0 -1 2 0 1 0 0 4 0 0 -1 -1 -1 0 0 -1 -1 0 2 0 -1 0 -1 0 -1 0 0 1 -1 4 -1 -1 -1 -1 2 -1 0 0 -1 3 2 -1 0 0 -1 3 -1 0 -1 0 1 3 2 2 -1 -1 0 3 1 -1 2 0 2 -1 0 -1 0 0 0 0 -1 0 0 3 -1 2 0 2 0 3 -1 3 0 -1 -1 0 2 0 -1 -1 1 0 0 1 4 0 0 -1 3 3 2 4 4 1 0 3 0 -1 0 0 -1 0 -1 -1 -1 0 2 0 0 -1 0 -1 0 0 4 0 2 0 -1 3 0 0 -1 0 -1 0 0 -1 3 -1 0 0 0 -1 -1 3 0 3 1 3 -1 3 0 -1 3 3 3 0 3 3 0 3 2 0 0 -1 0 2 -1 -1 -1 -1 -1 3 0 0 3 -1 3 3 -1 0 0 2 -1 -1 -1 0 2 0 2 -1 2 0 0 -1 0 3 -1 3 -1 0 2 0 3 0 -1 -1 0 -1 -1 3 -1 3 -1 0 0 1 0 -1 0 -1 0 0 1 0 0 0 0 2 0 -1 0 -1 -1 1 1 0 0 0 2 2 0 3 -1 -1 0 0 -1 -1 -1 4 0 -1 -1 0 4 2 -1 0 -1 0 4 -1 2 1 -1 0 3 0 -1 -1 0 -1 0 2 -1 2 3 0 0 2 0 4 -1 0 -1 2 1 -1 0 2 3 3 3 3 0 3 -1 0 3 0 3 2 0 0 0 2 -1 -1 -1 0 0 0 1 1 -1 3 0 2 -1 0 3 1 -1 -1 3 3 3 -1 -1 -1 1 -1 0 0 0 2 -1 1 0 1 1 -1 -1 0 2 0 0 0 0 2 0 -1 2 0 0 -1 1 -1 -1 0 -1 -1 0 -1 3 2 -1 3 0 0 2 -1 2 2 -1 3 -1 2 3 2 0 2 -1 3 3 0 0 -1 -1 0 0 2 -1 3 0 0 2 -1 2 0 0 0 0 2 -1 -1 -1 -1 0 -1 3 3 3 -1 3 0 2 2 0 -1 1 0 -1 2 0 -1 -1 -1 -1 1 1 1 3 3 -1 0 4 0 3 4 -1 2 0 0 0 0 -1 0 3 0 4 -1 -1 1 4 0 0 -1 -1 3 2 0 0 -1 0 0 3 2 -1 0 -1 -1 -1 -1 3 2 2 -1 -1 1 3 1 1 1 -1 2 -1 -1 1 0 3 3 0 0 -1 3 -1 4 1 4 0 2 2 0 0 1 -1 2 0 0 2 4 3 -1 3 -1 1 0 4 0 3 0 3 0 3 0 2 0 -1 2 3 0 0 -1 3 1 0 0 0 1 2 4 2 0 1 0 1 0 3 0 -1 0 2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/hh/qk4l6xwd65q9lfgxhl3nkd4w0000gn/T/ipykernel_814/1533788128.py\", line 1, in <module>\n      history = model.fit(X_train_vect, Y_train, batch_size=1024, epochs=8, validation_data=(X_test_vect, Y_test))\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 918, in compute_loss\n      return self.compiled_loss(\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 1862, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/backend.py\", line 5202, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of -1 which is outside the valid range of [0, 6).  Label values: 0 0 -1 4 3 -1 -1 0 0 3 3 -1 0 -1 -1 2 0 -1 0 0 0 0 0 0 3 3 -1 -1 0 2 0 -1 2 1 0 3 4 2 1 1 1 1 0 0 0 0 3 3 3 3 2 -1 -1 0 -1 -1 0 3 0 0 2 -1 3 0 1 0 0 -1 -1 3 0 3 4 4 0 0 0 0 0 0 -1 0 1 1 -1 0 0 1 -1 0 0 0 1 -1 0 -1 2 -1 0 0 -1 3 -1 0 -1 0 1 -1 -1 0 -1 0 0 2 2 2 -1 1 1 3 0 4 -1 -1 -1 -1 -1 -1 0 3 0 -1 2 0 -1 -1 2 0 0 -1 -1 -1 0 -1 2 -1 -1 2 0 -1 -1 2 3 0 -1 3 0 0 -1 0 2 2 -1 -1 1 2 0 2 3 3 2 0 0 4 0 0 -1 -1 0 2 2 0 1 0 2 0 2 1 3 -1 4 3 -1 1 -1 0 2 0 2 1 1 3 -1 3 2 -1 0 3 0 3 -1 0 0 -1 2 -1 3 -1 0 0 0 0 2 4 0 -1 -1 -1 -1 0 2 3 -1 1 1 3 0 4 1 0 0 0 0 -1 -1 0 2 -1 0 -1 1 -1 3 0 -1 3 -1 3 0 2 4 2 0 -1 2 0 2 0 -1 1 -1 0 0 4 4 3 -1 -1 2 2 2 -1 -1 3 0 -1 1 -1 -1 -1 1 0 0 -1 3 -1 2 3 1 -1 1 0 -1 0 2 2 0 3 0 0 2 1 3 3 0 1 2 0 0 -1 2 -1 3 4 0 0 -1 0 -1 -1 -1 3 2 3 -1 0 0 2 1 0 0 2 3 2 3 -1 2 0 0 -1 3 2 0 -1 0 0 0 -1 0 1 3 0 0 0 0 1 -1 3 0 -1 -1 2 -1 -1 0 2 -1 2 3 -1 4 2 2 -1 2 0 -1 0 3 -1 0 0 3 0 -1 3 0 0 -1 0 -1 1 -1 0 0 3 0 0 3 0 0 -1 3 2 -1 -1 0 2 2 1 1 0 1 3 2 2 4 -1 -1 2 0 0 0 2 -1 0 0 0 3 2 -1 0 2 0 0 0 2 2 -1 0 0 3 -1 0 1 -1 0 3 -1 0 -1 3 0 4 3 -1 3 -1 -1 0 -1 2 0 1 0 0 4 0 0 -1 -1 -1 0 0 -1 -1 0 2 0 -1 0 -1 0 -1 0 0 1 -1 4 -1 -1 -1 -1 2 -1 0 0 -1 3 2 -1 0 0 -1 3 -1 0 -1 0 1 3 2 2 -1 -1 0 3 1 -1 2 0 2 -1 0 -1 0 0 0 0 -1 0 0 3 -1 2 0 2 0 3 -1 3 0 -1 -1 0 2 0 -1 -1 1 0 0 1 4 0 0 -1 3 3 2 4 4 1 0 3 0 -1 0 0 -1 0 -1 -1 -1 0 2 0 0 -1 0 -1 0 0 4 0 2 0 -1 3 0 0 -1 0 -1 0 0 -1 3 -1 0 0 0 -1 -1 3 0 3 1 3 -1 3 0 -1 3 3 3 0 3 3 0 3 2 0 0 -1 0 2 -1 -1 -1 -1 -1 3 0 0 3 -1 3 3 -1 0 0 2 -1 -1 -1 0 2 0 2 -1 2 0 0 -1 0 3 -1 3 -1 0 2 0 3 0 -1 -1 0 -1 -1 3 -1 3 -1 0 0 1 0 -1 0 -1 0 0 1 0 0 0 0 2 0 -1 0 -1 -1 1 1 0 0 0 2 2 0 3 -1 -1 0 0 -1 -1 -1 4 0 -1 -1 0 4 2 -1 0 -1 0 4 -1 2 1 -1 0 3 0 -1 -1 0 -1 0 2 -1 2 3 0 0 2 0 4 -1 0 -1 2 1 -1 0 2 3 3 3 3 0 3 -1 0 3 0 3 2 0 0 0 2 -1 -1 -1 0 0 0 1 1 -1 3 0 2 -1 0 3 1 -1 -1 3 3 3 -1 -1 -1 1 -1 0 0 0 2 -1 1 0 1 1 -1 -1 0 2 0 0 0 0 2 0 -1 2 0 0 -1 1 -1 -1 0 -1 -1 0 -1 3 2 -1 3 0 0 2 -1 2 2 -1 3 -1 2 3 2 0 2 -1 3 3 0 0 -1 -1 0 0 2 -1 3 0 0 2 -1 2 0 0 0 0 2 -1 -1 -1 -1 0 -1 3 3 3 -1 3 0 2 2 0 -1 1 0 -1 2 0 -1 -1 -1 -1 1 1 1 3 3 -1 0 4 0 3 4 -1 2 0 0 0 0 -1 0 3 0 4 -1 -1 1 4 0 0 -1 -1 3 2 0 0 -1 0 0 3 2 -1 0 -1 -1 -1 -1 3 2 2 -1 -1 1 3 1 1 1 -1 2 -1 -1 1 0 3 3 0 0 -1 3 -1 4 1 4 0 2 2 0 0 1 -1 2 0 0 2 4 3 -1 3 -1 1 0 4 0 3 0 3 0 3 0 2 0 -1 2 3 0 0 -1 3 1 0 0 0 1 2 4 2 0 1 0 1 0 3 0 -1 0 2\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_732]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hh/qk4l6xwd65q9lfgxhl3nkd4w0000gn/T/ipykernel_814/1533788128.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/hh/qk4l6xwd65q9lfgxhl3nkd4w0000gn/T/ipykernel_814/1533788128.py\", line 1, in <module>\n      history = model.fit(X_train_vect, Y_train, batch_size=1024, epochs=8, validation_data=(X_test_vect, Y_test))\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 918, in compute_loss\n      return self.compiled_loss(\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 1862, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/Users/idriod/opt/anaconda3/lib/python3.9/site-packages/keras/backend.py\", line 5202, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of -1 which is outside the valid range of [0, 6).  Label values: 0 0 -1 4 3 -1 -1 0 0 3 3 -1 0 -1 -1 2 0 -1 0 0 0 0 0 0 3 3 -1 -1 0 2 0 -1 2 1 0 3 4 2 1 1 1 1 0 0 0 0 3 3 3 3 2 -1 -1 0 -1 -1 0 3 0 0 2 -1 3 0 1 0 0 -1 -1 3 0 3 4 4 0 0 0 0 0 0 -1 0 1 1 -1 0 0 1 -1 0 0 0 1 -1 0 -1 2 -1 0 0 -1 3 -1 0 -1 0 1 -1 -1 0 -1 0 0 2 2 2 -1 1 1 3 0 4 -1 -1 -1 -1 -1 -1 0 3 0 -1 2 0 -1 -1 2 0 0 -1 -1 -1 0 -1 2 -1 -1 2 0 -1 -1 2 3 0 -1 3 0 0 -1 0 2 2 -1 -1 1 2 0 2 3 3 2 0 0 4 0 0 -1 -1 0 2 2 0 1 0 2 0 2 1 3 -1 4 3 -1 1 -1 0 2 0 2 1 1 3 -1 3 2 -1 0 3 0 3 -1 0 0 -1 2 -1 3 -1 0 0 0 0 2 4 0 -1 -1 -1 -1 0 2 3 -1 1 1 3 0 4 1 0 0 0 0 -1 -1 0 2 -1 0 -1 1 -1 3 0 -1 3 -1 3 0 2 4 2 0 -1 2 0 2 0 -1 1 -1 0 0 4 4 3 -1 -1 2 2 2 -1 -1 3 0 -1 1 -1 -1 -1 1 0 0 -1 3 -1 2 3 1 -1 1 0 -1 0 2 2 0 3 0 0 2 1 3 3 0 1 2 0 0 -1 2 -1 3 4 0 0 -1 0 -1 -1 -1 3 2 3 -1 0 0 2 1 0 0 2 3 2 3 -1 2 0 0 -1 3 2 0 -1 0 0 0 -1 0 1 3 0 0 0 0 1 -1 3 0 -1 -1 2 -1 -1 0 2 -1 2 3 -1 4 2 2 -1 2 0 -1 0 3 -1 0 0 3 0 -1 3 0 0 -1 0 -1 1 -1 0 0 3 0 0 3 0 0 -1 3 2 -1 -1 0 2 2 1 1 0 1 3 2 2 4 -1 -1 2 0 0 0 2 -1 0 0 0 3 2 -1 0 2 0 0 0 2 2 -1 0 0 3 -1 0 1 -1 0 3 -1 0 -1 3 0 4 3 -1 3 -1 -1 0 -1 2 0 1 0 0 4 0 0 -1 -1 -1 0 0 -1 -1 0 2 0 -1 0 -1 0 -1 0 0 1 -1 4 -1 -1 -1 -1 2 -1 0 0 -1 3 2 -1 0 0 -1 3 -1 0 -1 0 1 3 2 2 -1 -1 0 3 1 -1 2 0 2 -1 0 -1 0 0 0 0 -1 0 0 3 -1 2 0 2 0 3 -1 3 0 -1 -1 0 2 0 -1 -1 1 0 0 1 4 0 0 -1 3 3 2 4 4 1 0 3 0 -1 0 0 -1 0 -1 -1 -1 0 2 0 0 -1 0 -1 0 0 4 0 2 0 -1 3 0 0 -1 0 -1 0 0 -1 3 -1 0 0 0 -1 -1 3 0 3 1 3 -1 3 0 -1 3 3 3 0 3 3 0 3 2 0 0 -1 0 2 -1 -1 -1 -1 -1 3 0 0 3 -1 3 3 -1 0 0 2 -1 -1 -1 0 2 0 2 -1 2 0 0 -1 0 3 -1 3 -1 0 2 0 3 0 -1 -1 0 -1 -1 3 -1 3 -1 0 0 1 0 -1 0 -1 0 0 1 0 0 0 0 2 0 -1 0 -1 -1 1 1 0 0 0 2 2 0 3 -1 -1 0 0 -1 -1 -1 4 0 -1 -1 0 4 2 -1 0 -1 0 4 -1 2 1 -1 0 3 0 -1 -1 0 -1 0 2 -1 2 3 0 0 2 0 4 -1 0 -1 2 1 -1 0 2 3 3 3 3 0 3 -1 0 3 0 3 2 0 0 0 2 -1 -1 -1 0 0 0 1 1 -1 3 0 2 -1 0 3 1 -1 -1 3 3 3 -1 -1 -1 1 -1 0 0 0 2 -1 1 0 1 1 -1 -1 0 2 0 0 0 0 2 0 -1 2 0 0 -1 1 -1 -1 0 -1 -1 0 -1 3 2 -1 3 0 0 2 -1 2 2 -1 3 -1 2 3 2 0 2 -1 3 3 0 0 -1 -1 0 0 2 -1 3 0 0 2 -1 2 0 0 0 0 2 -1 -1 -1 -1 0 -1 3 3 3 -1 3 0 2 2 0 -1 1 0 -1 2 0 -1 -1 -1 -1 1 1 1 3 3 -1 0 4 0 3 4 -1 2 0 0 0 0 -1 0 3 0 4 -1 -1 1 4 0 0 -1 -1 3 2 0 0 -1 0 0 3 2 -1 0 -1 -1 -1 -1 3 2 2 -1 -1 1 3 1 1 1 -1 2 -1 -1 1 0 3 3 0 0 -1 3 -1 4 1 4 0 2 2 0 0 1 -1 2 0 0 2 4 3 -1 3 -1 1 0 4 0 3 0 3 0 3 0 2 0 -1 2 3 0 0 -1 3 1 0 0 0 1 2 4 2 0 1 0 1 0 3 0 -1 0 2\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_732]"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_vect, Y_train, batch_size=1024, epochs=8, validation_data=(X_test_vect, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ---------------------------NOT YET----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataframes from Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotions\n",
       "0  i feel awful about it too because it s my job ...  sadness\n",
       "1                              im alone i feel awful  sadness\n",
       "2  ive probably mentioned this before but i reall...      joy\n",
       "3           i was feeling a little low few days back  sadness\n",
       "4  i beleive that i am much more sensitive to oth...     love"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =pickle.load(open('data/second_data/merged_training.pkl','rb'))\n",
    "new_df = pd.DataFrame(data).reset_index(drop=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA on Second Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='emotions', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=new_df['emotions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         141067\n",
       "sadness     121187\n",
       "anger        57317\n",
       "fear         47712\n",
       "love         34554\n",
       "surprise     14972\n",
       "Name: emotions, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['emotions'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on Second Dataset with Bag of Words Vectorizer and Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i also feel disillusioned that someone who cla...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wish you knew every word i write i write for...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotions\n",
       "0  i feel awful about it too because it s my job ...  sadness\n",
       "1                              im alone i feel awful  sadness\n",
       "2           i was feeling a little low few days back  sadness\n",
       "3  i also feel disillusioned that someone who cla...  sadness\n",
       "4  i wish you knew every word i write i write for...  sadness"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am one of those people who feels like going ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel especially pleased about this as this h...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was struggling with these awful feelings and...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i mean is on this stupid trip of making the gr...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotions\n",
       "0  ive probably mentioned this before but i reall...      joy\n",
       "1  i am one of those people who feels like going ...      joy\n",
       "2  i feel especially pleased about this as this h...      joy\n",
       "3  i was struggling with these awful feelings and...      joy\n",
       "4  i mean is on this stupid trip of making the gr...      joy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i find myself frustrated with christians becau...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel blessed everyday for our little man and...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i alternate between feeling sympathetic toward...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel passionate about today because of him</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotions\n",
       "0  i beleive that i am much more sensitive to oth...     love\n",
       "1  i find myself frustrated with christians becau...     love\n",
       "2  i feel blessed everyday for our little man and...     love\n",
       "3  i alternate between feeling sympathetic toward...     love\n",
       "4       i feel passionate about today because of him     love"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel so enraged but helpless at the same time</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i said feeling a bit rebellious</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i woke up feeling particularly vile tried to i...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i could feel the vile moth burrowing its way i...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have a pretty bad feeling the last two books...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotions\n",
       "0    i feel so enraged but helpless at the same time    anger\n",
       "1                    i said feeling a bit rebellious    anger\n",
       "2  i woke up feeling particularly vile tried to i...    anger\n",
       "3  i could feel the vile moth burrowing its way i...    anger\n",
       "4  i have a pretty bad feeling the last two books...    anger"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel weird knowing mine died when i wasn t a...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i don t like to feel uncomfortable with being ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i apologize to him almost every day for my lac...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i see things so clearly and with so much depth...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel doubtful about my place in the world of...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotions\n",
       "0  i feel weird knowing mine died when i wasn t a...     fear\n",
       "1  i don t like to feel uncomfortable with being ...     fear\n",
       "2  i apologize to him almost every day for my lac...     fear\n",
       "3  i see things so clearly and with so much depth...     fear\n",
       "4  i feel doubtful about my place in the world of...     fear"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i pretty much waddled out of the hospital feel...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i cant even imagine how my mom and her three y...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would recommend watching them to feel amazed...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i feel that i have a really funny side that i ...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can say that i feel amazed</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotions\n",
       "0  i pretty much waddled out of the hospital feel...  surprise\n",
       "1  i cant even imagine how my mom and her three y...  surprise\n",
       "2  i would recommend watching them to feel amazed...  surprise\n",
       "3  i feel that i have a really funny side that i ...  surprise\n",
       "4                       i can say that i feel amazed  surprise"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Made a copy of the data frame\n",
    "new_df_10000_2 = new_df.copy()\n",
    "\n",
    "#Getting 10k Sadness\n",
    "sadness_df = new_df_10000_2[new_df_10000_2['emotions'] == 'sadness']\n",
    "sadness_df_10000 = sadness_df.iloc[:10000].reset_index(drop=True)\n",
    "display(sadness_df_10000.shape)\n",
    "display(sadness_df_10000.head())\n",
    "\n",
    "#Getting 10k Joy\n",
    "joy_df = new_df_10000_2[new_df_10000_2['emotions'] == 'joy']\n",
    "joy_df_10000 = joy_df.iloc[:10000].reset_index(drop=True)\n",
    "display(joy_df_10000.shape)\n",
    "display(joy_df_10000.head())\n",
    "\n",
    "#Getting 10k Love\n",
    "love_df = new_df_10000_2[new_df_10000_2['emotions'] == 'love']\n",
    "love_df_10000 = love_df.iloc[:10000].reset_index(drop=True)\n",
    "display(love_df_10000.shape)\n",
    "display(love_df_10000.head())\n",
    "\n",
    "#Getting 10k Anger\n",
    "anger_df = new_df_10000_2[new_df_10000_2['emotions'] == 'anger']\n",
    "anger_df_10000 = anger_df.iloc[:10000].reset_index(drop=True)\n",
    "display(anger_df_10000.shape)\n",
    "display(anger_df_10000.head())\n",
    "\n",
    "#Getting 10k Fear\n",
    "fear_df = new_df_10000_2[new_df_10000_2['emotions'] == 'fear']\n",
    "fear_df_10000 = fear_df.iloc[:10000].reset_index(drop=True)\n",
    "display(fear_df_10000.shape)\n",
    "display(fear_df_10000.head())\n",
    "\n",
    "#Getting 10k Surprise\n",
    "surprise_df = new_df_10000_2[new_df_10000_2['emotions'] == 'surprise']\n",
    "surprise_df_10000 = surprise_df.iloc[:10000].reset_index(drop=True)\n",
    "display(surprise_df_10000.shape)\n",
    "display(surprise_df_10000.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYGklEQVR4nO3df7RdZX3n8ffHRCFgQZDAYAKGatQCVjQZClKVihVqVRiFGkckKDOpLPzV5WoH2i51bDO11XYqWpiiIgF/IKIFaovIpAJT5Vf4oeGHlCxBSIkQrSJoRcHv/LGfWw4394ab7Nxzcs37tdZZZ59n/3qec+7dn/Psfc5zUlVIkrS5njDqCkiSZjaDRJLUi0EiSerFIJEk9WKQSJJ6mT3qCgzbbrvtVgsWLBh1NSRpRrnuuuu+W1VzJ5q3zQXJggULWLVq1airIUkzSpJvTzbPU1uSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPUybUGS5Mwk9yW5aaBs1ySXJrm93e8yMO+UJGuS3Jbk8IHyRUlWt3mnJkkr3y7JZ1v51UkWTFdbJEmTm84eyVnAEePKTgZWVtVCYGV7TJJ9gSXAfm2d05LMauucDiwDFrbb2DZPAL5fVc8E/jfw59PWEknSpKYtSKrqCuDfxhUfCaxo0yuAowbKz62qh6rqDmANcGCSPYGdqurK6n445exx64xt63zgsLHeiiRpeIb9zfY9qmodQFWtS7J7K58HXDWw3NpW9rM2Pb58bJ2727YeTnI/8FTgu+N3mmQZXa+Gvffee8KKLfr9szevRSNy3QeOm/Kyd73vudNYk+mx97tXT3nZQz58yDTWZHp89W1fnfKyl7/4JdNYk+nxkisun/KyH3nX309jTba8t/7lqzZp+eXHHj1NNZkef/TJ8zd5na3lYvtEPYnaSPnG1tmwsOqMqlpcVYvnzp1wqBhJ0mYadpDc205X0e7va+Vrgb0GlpsP3NPK509Q/ph1kswGdmbDU2mSpGk27CC5CFjappcCFw6UL2mfxNqH7qL6Ne002ANJDmrXP44bt87Yto4G/qn8AXpJGrppu0aS5DPAocBuSdYC7wHeD5yX5ATgLuAYgKq6Ocl5wC3Aw8BJVfVI29SJdJ8AmwNc3G4AHwfOSbKGrieyZLraIkma3LQFSVW9fpJZh02y/HJg+QTlq4D9Jyj/CS2IJEmjs7VcbJckzVAGiSSpF4NEktSLQSJJ6sUgkST1YpBIknoxSCRJvRgkkqReDBJJUi8GiSSpF4NEktSLQSJJ6sUgkST1YpBIknoxSCRJvRgkkqReDBJJUi8GiSSpF4NEktSLQSJJ6sUgkST1YpBIknoxSCRJvRgkkqReDBJJUi8GiSSpF4NEktSLQSJJ6sUgkST1YpBIknoxSCRJvRgkkqReRhIkSX4vyc1JbkrymSTbJ9k1yaVJbm/3uwwsf0qSNUluS3L4QPmiJKvbvFOTZBTtkaRt2dCDJMk84O3A4qraH5gFLAFOBlZW1UJgZXtMkn3b/P2AI4DTksxqmzsdWAYsbLcjhtgUSRKjO7U1G5iTZDawA3APcCSwos1fARzVpo8Ezq2qh6rqDmANcGCSPYGdqurKqirg7IF1JElDMvQgqap/BT4I3AWsA+6vqi8De1TVurbMOmD3tso84O6BTaxtZfPa9PjyDSRZlmRVklXr16/fks2RpG3eKE5t7ULXy9gHeBqwY5JjN7bKBGW1kfINC6vOqKrFVbV47ty5m1plSdJGjOLU1suAO6pqfVX9DPgC8ELg3na6inZ/X1t+LbDXwPrz6U6FrW3T48slSUM0iiC5CzgoyQ7tU1aHAbcCFwFL2zJLgQvb9EXAkiTbJdmH7qL6Ne301wNJDmrbOW5gHUnSkMwe9g6r6uok5wPXAw8DNwBnAE8GzktyAl3YHNOWvznJecAtbfmTquqRtrkTgbOAOcDF7SZJGqKhBwlAVb0HeM+44ofoeicTLb8cWD5B+Spg/y1eQUnSlPnNdklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF5GEiRJnpLk/CTfTHJrkoOT7Jrk0iS3t/tdBpY/JcmaJLclOXygfFGS1W3eqUkyivZI0rZsVD2SDwFfqqrnAM8DbgVOBlZW1UJgZXtMkn2BJcB+wBHAaUlmte2cDiwDFrbbEcNshCRpBEGSZCfgxcDHAarqp1X1A+BIYEVbbAVwVJs+Eji3qh6qqjuANcCBSfYEdqqqK6uqgLMH1pEkDckoeiS/DKwHPpHkhiQfS7IjsEdVrQNo97u35ecBdw+sv7aVzWvT48slSUM0iiCZDbwAOL2qng/8iHYaaxITXfeojZRvuIFkWZJVSVatX79+U+srSdqIUQTJWmBtVV3dHp9PFyz3ttNVtPv7Bpbfa2D9+cA9rXz+BOUbqKozqmpxVS2eO3fuFmuIJGkEQVJV3wHuTvLsVnQYcAtwEbC0lS0FLmzTFwFLkmyXZB+6i+rXtNNfDyQ5qH1a67iBdSRJQzJ7RPt9G/CpJE8CvgW8iS7UzktyAnAXcAxAVd2c5Dy6sHkYOKmqHmnbORE4C5gDXNxukqQhmlKQJFlZVYc9XtlUVdWNwOIJZk24vapaDiyfoHwVsP/m1EGStGVsNEiSbA/sAOzWviA4doF7J+Bp01w3SdIM8Hg9kt8F3kkXGtfxaJD8EPib6auWJGmm2GiQVNWHgA8leVtVfXhIdZIkzSBTukZSVR9O8kJgweA6VXX2NNVLkjRDTPVi+znAM4AbgbFPTI0NSyJJ2oZN9eO/i4F925hWkiT9h6l+IfEm4D9NZ0UkSTPTVHskuwG3JLkGeGissKpePS21kiTNGFMNkvdOZyUkSTPXVD+1dfl0V0SSNDNN9VNbD/DoEO1PAp4I/KiqdpquikmSZoap9kh+afBxkqOAA6ejQpKkmWWzhpGvqguAl27ZqkiSZqKpntp6zcDDJ9B9r8TvlEiSpvyprVcNTD8M3AkcucVrI0macaZ6jeRN010RSdLMNKVrJEnmJ/m7JPcluTfJ55PMf/w1JUm/6KZ6sf0TdL+d/jRgHvD3rUyStI2bapDMrapPVNXD7XYWMHca6yVJmiGmGiTfTXJsklntdizwvemsmCRpZphqkLwZ+B3gO8A64GjAC/CSpCl//PdPgKVV9X2AJLsCH6QLGEnSNmyqPZJfHQsRgKr6N+D501MlSdJMMtUgeUKSXcYetB7JVHszkqRfYFMNg78EvpbkfLqhUX4HWD5ttZIkzRhT/Wb72UlW0Q3UGOA1VXXLtNZMkjQjTPn0VAsOw0OS9BibNYy8JEljDBJJUi8GiSSpF4NEktSLQSJJ6sUgkST1MrIgaaMI35Dki+3xrkkuTXJ7ux/8Jv0pSdYkuS3J4QPli5KsbvNOTZJRtEWStmWj7JG8A7h14PHJwMqqWgisbI9Jsi+wBNgPOAI4Lcmsts7pwDJgYbsdMZyqS5LGjCRI2s/0/jbwsYHiI4EVbXoFcNRA+blV9VBV3QGsAQ5MsiewU1VdWVUFnD2wjiRpSEbVI/lr4A+Anw+U7VFV6wDa/e6tfB5w98Bya1vZvDY9vnwDSZYlWZVk1fr167dIAyRJnaEHSZJXAvdV1XVTXWWCstpI+YaFVWdU1eKqWjx3rr8QLElb0iiGgj8EeHWSVwDbAzsl+SRwb5I9q2pdO211X1t+LbDXwPrzgXta+fwJyiVJQzT0HklVnVJV86tqAd1F9H+qqmOBi4ClbbGlwIVt+iJgSZLtkuxDd1H9mnb664EkB7VPax03sI4kaUi2ph+nej9wXpITgLuAYwCq6uYk59GNPPwwcFJVPdLWORE4C5gDXNxukqQhGmmQVNVlwGVt+nvAYZMst5wJfkirqlYB+09fDSVJj8dvtkuSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPUy9CBJsleSryS5NcnNSd7RyndNcmmS29v9LgPrnJJkTZLbkhw+UL4oyeo279QkGXZ7JGlbN4oeycPAu6rqV4CDgJOS7AucDKysqoXAyvaYNm8JsB9wBHBaklltW6cDy4CF7XbEMBsiSRpBkFTVuqq6vk0/ANwKzAOOBFa0xVYAR7XpI4Fzq+qhqroDWAMcmGRPYKequrKqCjh7YB1J0pCM9BpJkgXA84GrgT2qah10YQPs3habB9w9sNraVjavTY8vn2g/y5KsSrJq/fr1W7QNkrStG1mQJHky8HngnVX1w40tOkFZbaR8w8KqM6pqcVUtnjt37qZXVpI0qZEESZIn0oXIp6rqC6343na6inZ/XytfC+w1sPp84J5WPn+CcknSEI3iU1sBPg7cWlV/NTDrImBpm14KXDhQviTJdkn2obuofk07/fVAkoPaNo8bWEeSNCSzR7DPQ4A3AquT3NjK/hB4P3BekhOAu4BjAKrq5iTnAbfQfeLrpKp6pK13InAWMAe4uN0kSUM09CCpqn9m4usbAIdNss5yYPkE5auA/bdc7SRJm8pvtkuSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSepnxQZLkiCS3JVmT5ORR10eStjUzOkiSzAL+BvgtYF/g9Un2HW2tJGnbMqODBDgQWFNV36qqnwLnAkeOuE6StE1JVY26DpstydHAEVX139rjNwK/VlVvHbfcMmBZe/hs4LYhVnM34LtD3N+w2b6Z6xe5bWD7trSnV9XciWbMHmIlpkMmKNsgGavqDOCM6a/OhpKsqqrFo9j3MNi+mesXuW1g+4Zppp/aWgvsNfB4PnDPiOoiSdukmR4k1wILk+yT5EnAEuCiEddJkrYpM/rUVlU9nOStwCXALODMqrp5xNUabySn1IbI9s1cv8htA9s3NDP6YrskafRm+qktSdKIGSSSpF4Mki0kyYIkN426HtMlyddGXYctKcmDo66DNl+Stye5NcmnRl2XrU2Sf0zylKHu02skW0aSBcAXq2r/UddFjy/Jg1X15FHXY6ZJErrjxs9HXI9vAr9VVXf02MasqnpkC1ZrWiSZXVUPT2G5kb029kjGSbJjkn9I8vUkNyV5XZJ3J7m2PT6jvWAkWdSWuxI4aWAbxyf5QpIvJbk9yV8MzHt5kiuTXJ/kc0me3Mrfn+SWJN9I8sFWdkzb59eTXDHkp+IxkjyYzgdanVYneV2bd06SIweW/VSSV4+utlO3kTZ9NskrBpY7K8lrk8xqy1/bXqvfHV3tH5XkgiTXJbm5jeQw9potb38/VyXZo5U/oz2+Nsn7BntnSX5/oG3/s5UtaO/+TwOu57Hf3Rq6JP8H+GXgoiR/lOTMVucbxv4OW53/X/s/uz7JC1v5oUm+kuTTwOoh13uiY8udSXZr8xcnuaxNv7cda74MnN2OKRe2Y8ptSd4z0M7HvDZj25xof22dRUkub38vlyTZs3fjqsrbwA14LfDRgcc7A7sOPD4HeFWb/gbwkjb9AeCmNn088K227vbAt+n++XYDrgB2bMv9D+DdwK50w7aM9RCf0u5XA/MGy0b4vDzYnptL6T5qvQdwF7An8BLggoHn6w5g9qhfy8drz8DrPVGb/guwoi3zJOBuYA7dUDt/3Mq3A1YB+2wF7dm13c8BbgKeSjfKw9jf6l8M1PuLwOvb9FsGnouX032kNHRvMr8IvBhYAPwcOGjU7Rxo753t/+l/Ace2sqcA/wLsCOwAbN/KFwKr2vShwI9G8ZpNcmy5E9itPV4MXNam3wtcB8xpj48H1rXXdew1XjzRazPw3Ey0vycCXwPmtrLX0X1tolfb7JFsaDXwsiR/nuRFVXU/8BtJrk6yGngpsF+SnekO7pe39c4Zt52VVXV/Vf0EuAV4OnAQ3SjFX01yI7C0lf8Q+AnwsSSvAX7ctvFV4Kwk/53uQDdqvw58pqoeqap7gcuB/9yeg2cm2R14PfD5mkJXfCsxYZuAi4GXJtmObnTpK6rq3+kOtse11+9qun/shSOp+WO9PcnXgavo3rQsBH5KFwbQHZQWtOmDgc+16U8PbOPl7XYD3bvb5/Bo275dVVdNV+V7eDlwcns9LqN747Y33QHzo+1/9nN0/3djrqkep8R6mOjYsjEXtb+5MZdW1fda2Rfo/nZh8tdmov09G9gfuLQ9Z39MNyJILzP6C4nToar+Jcki4BXAn7Wu5UnA4qq6O8l76f5YwwTjeg14aGD6EbrnOnR/DK8fv3CSA4HD6L6d/1bgpVX1liS/Bvw2cGOSA6rqe70bufkmGttszDnAG+jq/+bhVGeLmLBNVfWTdprhcLp3bZ8ZWP5tVXXJcKr3+JIcCrwMOLiqftzqvT3ws2pvO3n0b3CjmwL+rKr+dtz2F9C9i98aBXhtVT1mINb2f3ov8Dy63tVPBmaPpC2THFse5tFLDNuPW2V8Pccfb2qS5Ta2v78Dbq6qgzezGROyRzJOkqcBP66qTwIfBF7QZn033fWMowGq6gfA/UnG3hW8YQqbvwo4JMkz2752SPKstt2dq+ofgXcCB7T5z6iqq6vq3XSjfI703DTdabnXtesEc+lOe1zT5p1FV3dq6xtdYGM21qZzgTcBL6IbPYF2f2KSJwK012/HIdd5vJ2B77cQeQ5dz3djrqI77QFd8I+5BHhzHr1uN6/1MrdmlwBvS/7juuXzW/nOwLrqLjy/ka2gRz/JseVOYFFb5LWTrDrmN5PsmmQOcBTdGYtN3d9twNwkB7dlnphkv81r0aPskWzoucAHkvwc+BlwIt2LtpruRb92YNk3AWcm+TGPHmgmVVXrkxwPfKadMoGua/kAcGGSsZ7O77V5H0iysJWtBL7eq2X9FN27mYNbPQr4g6r6DkBV3ZvkVuCCkdVw80zaJuDLwNl0pxh+2so+RneK6Pp28FpP9/cxSl8C3pLkG3QHisc7BfVO4JNJ3gX8A3A/QFV9OcmvAFe24/KDwLF0vZmt1Z8Afw18o70edwKvBE4DPp/kGOArbB09qomOLXOAjyf5Q7pTpRvzz3Q9/2cCn66qVa23OOX9VdVP0/38xqnt9Pxsuuev15s/P/6rx5XkqcD1VfX0jSyzA13YvmAK5341Qu21+veqqiRL6C68+4NwW7H2BnRxjfutpa2FPRJtVOseX0bXNZ5smZcBZwJ/ZYjMCIuAj7R38D9gZl3T0lbIHokkqRcvtkuSejFIJEm9GCSSpF4MEmkrkOSAPHZsr1cnOXmUdZKmyovt0lZga/94p7Qx9kikzZDk2CTXJLkxyd+2b8Y/2MY1ui7J/01yYJLLknwrbTTkJNsn+US6kYZvSPIbSZ4EvI/uG/Y3phsV9vgkH2nrPD3JynQj8q5MsncrPyvJqUm+1vZxdCvfM8kVbVs3JXnRqJ4nbRsMEmkTtW9/vw44pKoOoPvm9xvoRp29rKoW0Y1W8KfAb9KNJPy+tvpJAFX1XLoBLlfQ/R++G/hsVR1QVZ8dt8uPAGdX1a8CnwJOHZi3J93gfa8E3t/K/itwSavb84Abt0S7pcn4hURp0x1G96W+a9tQInOA++hG2/1SW2Y18FBV/SzdCLQLWvmvAx8GqKpvJvk28KzH2d/BwGva9Dl0Q8KPuaCNJ3VL2u+N0A3jc2YbD+yCqrpxcxopTZU9EmnThe63Sg5ot2dX1Xt57Gi7P6eNAN0O9LMH1u1r8MLm4CjTafu7gm7wyX8Fzkly3BbYpzQpg0TadCuBo8dGxm0jsk46Dtk4V9BGik7yLLrfzriN7lTYL02yztd4dJTeN9AN3jepVpf7quqjwMd5dARraVoYJNImqqpb6EZt/nIbcfdSumsVU3EaMKud7voscHxVPUQ3Qu2+Yxfbx63zduBNbV9vBN7xOPs4lO73a26gG5r8Q1Osm7RZ/PivJKkXeySSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSevn/RjED5TZ1QBYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Concated all the serparted data frames of all the emotions and but them back together\n",
    "all_10k_df = pd.concat([sadness_df_10000, joy_df_10000, love_df_10000, anger_df_10000, fear_df_10000, surprise_df_10000])\n",
    "sns.countplot(x=all_10k_df['emotions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:  i feel awful about it too because it s my job to get him in a position to succeed and it just didn t happen here\n",
      "Cleaned test:  i feel awful about it too because it s my job to get him in a position to succeed and it just didn t happen here\n"
     ]
    }
   ],
   "source": [
    "#creating new column with cleaned up text\n",
    "all_10k_df['cleaned_text'] = all_10k_df['text'].apply(clean_tweets_without_nlp)\n",
    "print(\"Original text: \", all_10k_df.iloc[0]['text'])\n",
    "print(\"Cleaned test: \", all_10k_df.iloc[0]['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:  i feel awful about it too because it s my job to get him in a position to succeed and it just didn t happen here\n",
      "Stemmed test:  feel aw job get posit succeed happen\n"
     ]
    }
   ],
   "source": [
    "#creating new column with stemmed cleaned up text\n",
    "all_10k_df['cleaned_text_stem'] = all_10k_df['text'].apply(clean_tweets_with_stem)\n",
    "print(\"Original text: \", all_10k_df.iloc[0]['text'])\n",
    "print(\"Stemmed test: \", all_10k_df.iloc[0]['cleaned_text_stem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:  i feel awful about it too because it s my job to get him in a position to succeed and it just didn t happen here\n",
      "Lemmized test:  feel awful job get position succeed happen\n"
     ]
    }
   ],
   "source": [
    "#creating new colum with lemmzed cleaned up text\n",
    "all_10k_df['cleaned_text_lem'] = all_10k_df['text'].apply(clean_tweets_with_lem)\n",
    "print(\"Original text: \", all_10k_df.iloc[0]['text'])\n",
    "print(\"Lemmized test: \", all_10k_df.iloc[0]['cleaned_text_lem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_text_stem</th>\n",
       "      <th>cleaned_text_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>feel aw job get posit succeed happen</td>\n",
       "      <td>feel awful job get position succeed happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>im alon feel aw</td>\n",
       "      <td>im alone feel awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>feel littl low day back</td>\n",
       "      <td>feeling little low day back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i also feel disillusioned that someone who cla...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i also feel disillusioned that someone who cla...</td>\n",
       "      <td>also feel disillus someon claim valu truth fraud</td>\n",
       "      <td>also feel disillusioned someone claimed value ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wish you knew every word i write i write for...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i wish you knew every word i write i write for...</td>\n",
       "      <td>wish knew everi word write write think useless...</td>\n",
       "      <td>wish knew every word write write think useless...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotions  \\\n",
       "0  i feel awful about it too because it s my job ...  sadness   \n",
       "1                              im alone i feel awful  sadness   \n",
       "2           i was feeling a little low few days back  sadness   \n",
       "3  i also feel disillusioned that someone who cla...  sadness   \n",
       "4  i wish you knew every word i write i write for...  sadness   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  i feel awful about it too because it s my job ...   \n",
       "1                              im alone i feel awful   \n",
       "2           i was feeling a little low few days back   \n",
       "3  i also feel disillusioned that someone who cla...   \n",
       "4  i wish you knew every word i write i write for...   \n",
       "\n",
       "                                   cleaned_text_stem  \\\n",
       "0               feel aw job get posit succeed happen   \n",
       "1                                    im alon feel aw   \n",
       "2                            feel littl low day back   \n",
       "3   also feel disillus someon claim valu truth fraud   \n",
       "4  wish knew everi word write write think useless...   \n",
       "\n",
       "                                    cleaned_text_lem  \n",
       "0         feel awful job get position succeed happen  \n",
       "1                                im alone feel awful  \n",
       "2                        feeling little low day back  \n",
       "3  also feel disillusioned someone claimed value ...  \n",
       "4  wish knew every word write write think useless...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_10k_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_10k_df.columns #['text', 'label', 'cleaned_text', 'cleaned_text_stem', 'cleaned_text_lem']\n",
    "\n",
    "X = all_10k_df['cleaned_text'].values\n",
    "y = all_10k_df['emotions'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<60000x29838 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 945942 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hh/qk4l6xwd65q9lfgxhl3nkd4w0000gn/T/ipykernel_814/748242919.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = X.shape[1]\n",
    "embed_len = 128\n",
    "target_classes = all_10k_df['emotions'].unique()\n",
    "\n",
    "inputs = Input(shape=(max_tokens, ))\n",
    "embeddings_layer = Embedding(input_dim=1000, output_dim=embed_len, input_length=max_tokens)\n",
    "conv = Conv1D(32, 7, padding=\"same\") ## Channels last\n",
    "dense = Dense(len(target_classes), activation=\"softmax\")\n",
    "\n",
    "x = embeddings_layer(inputs)\n",
    "x = conv(x)\n",
    "x = tensorflow.reduce_max(x, axis=1)\n",
    "output = dense(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=1024, epochs=8, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
